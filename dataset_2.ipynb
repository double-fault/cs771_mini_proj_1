{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# read feature dataset\n",
    "train_seq_df = pd.read_csv(\"datasets/train/train_text_seq.csv\")\n",
    "train_seq_X = train_seq_df['input_str'].tolist()\n",
    "train_seq_Y = train_seq_df['label'].tolist()\n",
    "\n",
    "test_seq_X = pd.read_csv(\"datasets/test/test_text_seq.csv\")['input_str'].tolist()\n",
    "\n",
    "valid_seq_df = pd.read_csv(\"datasets/valid/valid_text_seq.csv\")\n",
    "valid_seq_X = valid_seq_df['input_str'].tolist()\n",
    "valid_seq_Y = valid_seq_df['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_11 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,301</span> (40.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,301\u001b[0m (40.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,301</span> (40.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,301\u001b[0m (40.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # Define the model architecture\n",
    "# def build_rnn(input_shape, num_units=50, num_layers=3, dropout_rate=0.2, output_size=1):\n",
    "#     model = models.Sequential()\n",
    "    \n",
    "#     # Add RNN layers\n",
    "#     for i in range(num_layers):\n",
    "#         if i == 0:\n",
    "#             # First layer requires input shape\n",
    "#             model.add(layers.SimpleRNN(units=num_units, return_sequences=True if num_layers > 1 else False,\n",
    "#                                        input_shape=input_shape))\n",
    "#         else:\n",
    "#             # For subsequent layers\n",
    "#             model.add(layers.SimpleRNN(units=num_units, return_sequences=True if i < num_layers - 1 else False))\n",
    "\n",
    "#         # Add dropout for regularization (optional)\n",
    "#         model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "#     # Output layer (e.g., for classification or regression)\n",
    "#     model.add(layers.Dense(units=output_size, activation='softmax' if output_size > 1 else 'sigmoid'))\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='categorical_crossentropy' if output_size > 1 else 'binary_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # Sample input\n",
    "# input_shape = (50, 1)  # (sequence length, number of features)\n",
    "# num_units = 100        # Number of RNN units\n",
    "# num_layers = 1  # Number of RNN layers\n",
    "# dropout_rate = 0.2     # Dropout rate to avoid overfitting\n",
    "# output_size = 1        # Single output (for binary classification)\n",
    "\n",
    "# # Build the model\n",
    "# model = build_rnn(input_shape, num_units=num_units, num_layers=num_layers, \n",
    "#                   dropout_rate=dropout_rate, output_size=output_size)\n",
    "\n",
    "# # Display model architecture\n",
    "# model.summary()\n",
    "\n",
    "# # Train the model (example)\n",
    "# # X_train: training data with shape (num_samples, sequence_length, num_features)\n",
    "# # y_train: corresponding labels\n",
    "# # model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[int(char) for char in sequence] for sequence in train_seq_X]\n",
    "X_valid = [[int(char) for char in sequence] for sequence in valid_seq_X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5050 - loss: 0.7298 - val_accuracy: 0.5603 - val_loss: 0.6902\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4974 - loss: 0.7152 - val_accuracy: 0.5010 - val_loss: 0.6996\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5251 - loss: 0.7060 - val_accuracy: 0.4724 - val_loss: 0.6987\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 0.6975 - val_accuracy: 0.4581 - val_loss: 0.7041\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5114 - loss: 0.7008 - val_accuracy: 0.5256 - val_loss: 0.6883\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5413 - loss: 0.6898 - val_accuracy: 0.5235 - val_loss: 0.6887\n",
      "Epoch 7/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5432 - loss: 0.6871 - val_accuracy: 0.5419 - val_loss: 0.6825\n",
      "Epoch 8/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5440 - loss: 0.6861 - val_accuracy: 0.5317 - val_loss: 0.6805\n",
      "Epoch 9/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5504 - loss: 0.6829 - val_accuracy: 0.5419 - val_loss: 0.6827\n",
      "Epoch 10/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 0.6829 - val_accuracy: 0.5562 - val_loss: 0.6839\n",
      "Epoch 11/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5716 - loss: 0.6792 - val_accuracy: 0.5726 - val_loss: 0.6725\n",
      "Epoch 12/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5521 - loss: 0.6780 - val_accuracy: 0.5644 - val_loss: 0.6736\n",
      "Epoch 13/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5911 - loss: 0.6702 - val_accuracy: 0.5644 - val_loss: 0.6716\n",
      "Epoch 14/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5836 - loss: 0.6712 - val_accuracy: 0.5665 - val_loss: 0.6704\n",
      "Epoch 15/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 0.6640 - val_accuracy: 0.5890 - val_loss: 0.6542\n",
      "Epoch 16/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6102 - loss: 0.6558 - val_accuracy: 0.6339 - val_loss: 0.6449\n",
      "Epoch 17/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 0.6593 - val_accuracy: 0.6258 - val_loss: 0.6461\n",
      "Epoch 18/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6248 - loss: 0.6451 - val_accuracy: 0.6258 - val_loss: 0.6525\n",
      "Epoch 19/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6290 - loss: 0.6470 - val_accuracy: 0.6115 - val_loss: 0.6434\n",
      "Epoch 20/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6338 - loss: 0.6381 - val_accuracy: 0.6278 - val_loss: 0.6428\n",
      "Epoch 21/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6372 - loss: 0.6390 - val_accuracy: 0.6421 - val_loss: 0.6414\n",
      "Epoch 22/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6371 - loss: 0.6337 - val_accuracy: 0.6483 - val_loss: 0.6324\n",
      "Epoch 23/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6576 - loss: 0.6238 - val_accuracy: 0.6196 - val_loss: 0.6553\n",
      "Epoch 24/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6624 - loss: 0.6286 - val_accuracy: 0.6380 - val_loss: 0.6330\n",
      "Epoch 25/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6672 - loss: 0.6145 - val_accuracy: 0.6585 - val_loss: 0.6465\n",
      "Epoch 26/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6736 - loss: 0.6032 - val_accuracy: 0.6605 - val_loss: 0.6347\n",
      "Epoch 27/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6685 - loss: 0.6098 - val_accuracy: 0.6810 - val_loss: 0.6243\n",
      "Epoch 28/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6796 - loss: 0.6058 - val_accuracy: 0.6421 - val_loss: 0.6454\n",
      "Epoch 29/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6865 - loss: 0.5972 - val_accuracy: 0.6585 - val_loss: 0.6248\n",
      "Epoch 30/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6911 - loss: 0.6003 - val_accuracy: 0.6667 - val_loss: 0.6257\n",
      "Epoch 31/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6886 - loss: 0.5903 - val_accuracy: 0.6483 - val_loss: 0.6375\n",
      "Epoch 32/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7054 - loss: 0.5847 - val_accuracy: 0.6708 - val_loss: 0.6317\n",
      "Epoch 33/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6962 - loss: 0.5908 - val_accuracy: 0.6646 - val_loss: 0.6450\n",
      "Epoch 34/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6983 - loss: 0.5852 - val_accuracy: 0.6646 - val_loss: 0.6402\n",
      "Epoch 35/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7047 - loss: 0.5830 - val_accuracy: 0.6728 - val_loss: 0.6314\n",
      "Epoch 36/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7018 - loss: 0.5810 - val_accuracy: 0.6708 - val_loss: 0.6317\n",
      "Epoch 37/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.5734 - val_accuracy: 0.6626 - val_loss: 0.6396\n",
      "Epoch 38/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7163 - loss: 0.5662 - val_accuracy: 0.6810 - val_loss: 0.6178\n",
      "Epoch 39/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7094 - loss: 0.5761 - val_accuracy: 0.6544 - val_loss: 0.6434\n",
      "Epoch 40/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7231 - loss: 0.5696 - val_accuracy: 0.6462 - val_loss: 0.6371\n",
      "Epoch 41/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7122 - loss: 0.5702 - val_accuracy: 0.6503 - val_loss: 0.6470\n",
      "Epoch 42/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7307 - loss: 0.5557 - val_accuracy: 0.6708 - val_loss: 0.6422\n",
      "Epoch 43/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7261 - loss: 0.5536 - val_accuracy: 0.6605 - val_loss: 0.6495\n",
      "Epoch 44/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7268 - loss: 0.5574 - val_accuracy: 0.6769 - val_loss: 0.6417\n",
      "Epoch 45/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7334 - loss: 0.5467 - val_accuracy: 0.6564 - val_loss: 0.6515\n",
      "Epoch 46/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7360 - loss: 0.5483 - val_accuracy: 0.6851 - val_loss: 0.6366\n",
      "Epoch 47/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7256 - loss: 0.5450 - val_accuracy: 0.6687 - val_loss: 0.6452\n",
      "Epoch 48/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7262 - loss: 0.5531 - val_accuracy: 0.6442 - val_loss: 0.6763\n",
      "Epoch 49/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7252 - loss: 0.5606 - val_accuracy: 0.6544 - val_loss: 0.6676\n",
      "Epoch 50/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7279 - loss: 0.5461 - val_accuracy: 0.6646 - val_loss: 0.6592\n",
      "Epoch 51/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.5441 - val_accuracy: 0.6524 - val_loss: 0.6474\n",
      "Epoch 52/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7366 - loss: 0.5381 - val_accuracy: 0.6524 - val_loss: 0.6384\n",
      "Epoch 53/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7444 - loss: 0.5353 - val_accuracy: 0.6503 - val_loss: 0.6551\n",
      "Epoch 54/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.5291 - val_accuracy: 0.6667 - val_loss: 0.6563\n",
      "Epoch 55/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7410 - loss: 0.5350 - val_accuracy: 0.6708 - val_loss: 0.6593\n",
      "Epoch 56/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7286 - loss: 0.5386 - val_accuracy: 0.6544 - val_loss: 0.6806\n",
      "Epoch 57/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7306 - loss: 0.5418 - val_accuracy: 0.6728 - val_loss: 0.6503\n",
      "Epoch 58/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7480 - loss: 0.5269 - val_accuracy: 0.6667 - val_loss: 0.6655\n",
      "Epoch 59/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7549 - loss: 0.5242 - val_accuracy: 0.6708 - val_loss: 0.6532\n",
      "Epoch 60/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7481 - loss: 0.5287 - val_accuracy: 0.6605 - val_loss: 0.6727\n",
      "Epoch 61/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7449 - loss: 0.5281 - val_accuracy: 0.6605 - val_loss: 0.6614\n",
      "Epoch 62/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7609 - loss: 0.5036 - val_accuracy: 0.6544 - val_loss: 0.6734\n",
      "Epoch 63/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.5083 - val_accuracy: 0.6748 - val_loss: 0.6732\n",
      "Epoch 64/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7581 - loss: 0.5119 - val_accuracy: 0.6646 - val_loss: 0.6772\n",
      "Epoch 65/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7489 - loss: 0.5233 - val_accuracy: 0.6626 - val_loss: 0.6787\n",
      "Epoch 66/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7644 - loss: 0.5046 - val_accuracy: 0.6626 - val_loss: 0.6835\n",
      "Epoch 67/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7614 - loss: 0.5094 - val_accuracy: 0.6544 - val_loss: 0.6929\n",
      "Epoch 68/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7665 - loss: 0.4988 - val_accuracy: 0.6585 - val_loss: 0.6998\n",
      "Epoch 69/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7513 - loss: 0.5134 - val_accuracy: 0.6646 - val_loss: 0.6887\n",
      "Epoch 70/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7521 - loss: 0.5124 - val_accuracy: 0.6339 - val_loss: 0.7333\n",
      "Epoch 71/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7555 - loss: 0.5070 - val_accuracy: 0.6524 - val_loss: 0.6902\n",
      "Epoch 72/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7612 - loss: 0.5156 - val_accuracy: 0.6421 - val_loss: 0.7143\n",
      "Epoch 73/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7675 - loss: 0.5056 - val_accuracy: 0.6483 - val_loss: 0.7368\n",
      "Epoch 74/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7617 - loss: 0.5042 - val_accuracy: 0.6483 - val_loss: 0.6887\n",
      "Epoch 75/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7555 - loss: 0.5104 - val_accuracy: 0.6564 - val_loss: 0.6843\n",
      "Epoch 76/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7637 - loss: 0.5032 - val_accuracy: 0.6524 - val_loss: 0.6986\n",
      "Epoch 77/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7679 - loss: 0.4935 - val_accuracy: 0.6483 - val_loss: 0.6763\n",
      "Epoch 78/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7573 - loss: 0.5081 - val_accuracy: 0.6544 - val_loss: 0.7038\n",
      "Epoch 79/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7678 - loss: 0.4951 - val_accuracy: 0.6748 - val_loss: 0.6845\n",
      "Epoch 80/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7771 - loss: 0.4778 - val_accuracy: 0.6360 - val_loss: 0.7123\n",
      "Epoch 81/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7684 - loss: 0.4985 - val_accuracy: 0.6483 - val_loss: 0.7271\n",
      "Epoch 82/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7768 - loss: 0.4815 - val_accuracy: 0.6605 - val_loss: 0.6807\n",
      "Epoch 83/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7757 - loss: 0.4911 - val_accuracy: 0.6585 - val_loss: 0.7408\n",
      "Epoch 84/100\n",
      "\u001b[1m189/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7654 - loss: 0.4994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_seq_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_seq_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(train_seq_Y), epochs=100, batch_size=32, validation_data=(np.array(X_valid), np.array(valid_seq_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model architecture\n",
    "def build_rnn(input_length=50, num_units=50, num_layers=1, dropout_rate=0.2, output_size=1):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Embedding layer: Input size 10 for digits 0-9, output size 8-dimensional embeddings\n",
    "    model.add(layers.Embedding(input_dim=10, output_dim=10, input_length=input_length))  # For 10 unique characters\n",
    "    \n",
    "    # Add RNN layers\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            # First RNN layer\n",
    "            model.add(layers.GRU(units=num_units, return_sequences=True if num_layers > 1 else False))\n",
    "        else:\n",
    "            # For subsequent layers\n",
    "            model.add(layers.GRU(units=num_units, return_sequences=True if i < num_layers - 1 else False))\n",
    "\n",
    "        # Add dropout for regularization\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    model.add(layers.Dense(units=output_size, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  # Use binary_crossentropy for binary classification\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Sample input parameters\n",
    "input_length = 50      # Sequence length (50 characters in the string)\n",
    "num_units = 50         # Number of RNN units\n",
    "num_layers = 1         # Number of RNN layers\n",
    "dropout_rate = 0.2     # Dropout rate to avoid overfitting\n",
    "output_size = 1        # Single output (for binary classification)\n",
    "\n",
    "# Build the model\n",
    "model = build_rnn(input_length=input_length, num_units=num_units, num_layers=num_layers, \n",
    "                  dropout_rate=dropout_rate, output_size=output_size)\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "model_RNN = model\n",
    "\n",
    "# Training (Example)\n",
    "# X_train should have shape (num_samples, sequence_length)\n",
    "# y_train should be binary labels (0 or 1)\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4925 - loss: 0.6936 - val_accuracy: 0.5133 - val_loss: 0.6923\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5240 - loss: 0.6917 - val_accuracy: 0.5951 - val_loss: 0.6755\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5804 - loss: 0.6738 - val_accuracy: 0.5787 - val_loss: 0.6570\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6186 - loss: 0.6535 - val_accuracy: 0.6667 - val_loss: 0.6373\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6357 - loss: 0.6430 - val_accuracy: 0.6605 - val_loss: 0.6297\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6476 - loss: 0.6367 - val_accuracy: 0.6605 - val_loss: 0.6357\n",
      "Epoch 7/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6570 - loss: 0.6276 - val_accuracy: 0.6830 - val_loss: 0.6201\n",
      "Epoch 8/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6597 - loss: 0.6246 - val_accuracy: 0.6442 - val_loss: 0.6187\n",
      "Epoch 9/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6555 - loss: 0.6170 - val_accuracy: 0.6667 - val_loss: 0.6169\n",
      "Epoch 10/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6714 - loss: 0.6143 - val_accuracy: 0.6667 - val_loss: 0.6200\n",
      "Epoch 11/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6615 - loss: 0.6087 - val_accuracy: 0.6810 - val_loss: 0.6037\n",
      "Epoch 12/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6613 - loss: 0.6104 - val_accuracy: 0.6687 - val_loss: 0.6072\n",
      "Epoch 13/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6708 - loss: 0.5986 - val_accuracy: 0.6871 - val_loss: 0.6094\n",
      "Epoch 14/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6829 - loss: 0.5957 - val_accuracy: 0.6912 - val_loss: 0.6014\n",
      "Epoch 15/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6829 - loss: 0.5894 - val_accuracy: 0.6892 - val_loss: 0.5958\n",
      "Epoch 16/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6825 - loss: 0.5892 - val_accuracy: 0.6953 - val_loss: 0.6043\n",
      "Epoch 17/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6825 - loss: 0.5895 - val_accuracy: 0.7035 - val_loss: 0.5984\n",
      "Epoch 18/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6876 - loss: 0.5795 - val_accuracy: 0.6851 - val_loss: 0.5957\n",
      "Epoch 19/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7057 - loss: 0.5686 - val_accuracy: 0.6892 - val_loss: 0.5898\n",
      "Epoch 20/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7036 - loss: 0.5666 - val_accuracy: 0.7014 - val_loss: 0.5767\n",
      "Epoch 21/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7073 - loss: 0.5554 - val_accuracy: 0.7035 - val_loss: 0.5758\n",
      "Epoch 22/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7116 - loss: 0.5473 - val_accuracy: 0.7014 - val_loss: 0.5751\n",
      "Epoch 23/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7275 - loss: 0.5368 - val_accuracy: 0.7055 - val_loss: 0.5517\n",
      "Epoch 24/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7365 - loss: 0.5203 - val_accuracy: 0.7301 - val_loss: 0.5357\n",
      "Epoch 25/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7556 - loss: 0.4916 - val_accuracy: 0.7239 - val_loss: 0.5319\n",
      "Epoch 26/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7651 - loss: 0.4868 - val_accuracy: 0.7219 - val_loss: 0.5266\n",
      "Epoch 27/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7634 - loss: 0.4818 - val_accuracy: 0.7464 - val_loss: 0.5025\n",
      "Epoch 28/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.4687 - val_accuracy: 0.7382 - val_loss: 0.5126\n",
      "Epoch 29/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7748 - loss: 0.4595 - val_accuracy: 0.7628 - val_loss: 0.4784\n",
      "Epoch 30/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7881 - loss: 0.4469 - val_accuracy: 0.7648 - val_loss: 0.4874\n",
      "Epoch 31/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8006 - loss: 0.4197 - val_accuracy: 0.7628 - val_loss: 0.4738\n",
      "Epoch 32/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8033 - loss: 0.4153 - val_accuracy: 0.7873 - val_loss: 0.4666\n",
      "Epoch 33/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8084 - loss: 0.4050 - val_accuracy: 0.7771 - val_loss: 0.4690\n",
      "Epoch 34/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8085 - loss: 0.4036 - val_accuracy: 0.7791 - val_loss: 0.4613\n",
      "Epoch 35/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8226 - loss: 0.3936 - val_accuracy: 0.7873 - val_loss: 0.4465\n",
      "Epoch 36/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8261 - loss: 0.3788 - val_accuracy: 0.7894 - val_loss: 0.4483\n",
      "Epoch 37/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8423 - loss: 0.3562 - val_accuracy: 0.7975 - val_loss: 0.4313\n",
      "Epoch 38/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8469 - loss: 0.3438 - val_accuracy: 0.8016 - val_loss: 0.4749\n",
      "Epoch 39/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8511 - loss: 0.3395 - val_accuracy: 0.8139 - val_loss: 0.4402\n",
      "Epoch 40/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8522 - loss: 0.3253 - val_accuracy: 0.8241 - val_loss: 0.4217\n",
      "Epoch 41/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8674 - loss: 0.3110 - val_accuracy: 0.8303 - val_loss: 0.4123\n",
      "Epoch 42/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8669 - loss: 0.2996 - val_accuracy: 0.8139 - val_loss: 0.4071\n",
      "Epoch 43/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8702 - loss: 0.2935 - val_accuracy: 0.8078 - val_loss: 0.4279\n",
      "Epoch 44/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8732 - loss: 0.2821 - val_accuracy: 0.8200 - val_loss: 0.4126\n",
      "Epoch 45/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8844 - loss: 0.2698 - val_accuracy: 0.8262 - val_loss: 0.4344\n",
      "Epoch 46/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8813 - loss: 0.2671 - val_accuracy: 0.8282 - val_loss: 0.4276\n",
      "Epoch 47/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8985 - loss: 0.2458 - val_accuracy: 0.8200 - val_loss: 0.4183\n",
      "Epoch 48/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9031 - loss: 0.2432 - val_accuracy: 0.8200 - val_loss: 0.4569\n",
      "Epoch 49/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8977 - loss: 0.2302 - val_accuracy: 0.8221 - val_loss: 0.4638\n",
      "Epoch 50/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9060 - loss: 0.2242 - val_accuracy: 0.8323 - val_loss: 0.4045\n",
      "Epoch 51/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9102 - loss: 0.2161 - val_accuracy: 0.8221 - val_loss: 0.4893\n",
      "Epoch 52/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9124 - loss: 0.2078 - val_accuracy: 0.8262 - val_loss: 0.4593\n",
      "Epoch 53/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9197 - loss: 0.2002 - val_accuracy: 0.8303 - val_loss: 0.4273\n",
      "Epoch 54/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.1826 - val_accuracy: 0.8200 - val_loss: 0.4897\n",
      "Epoch 55/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9236 - loss: 0.1872 - val_accuracy: 0.8282 - val_loss: 0.5045\n",
      "Epoch 56/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9322 - loss: 0.1720 - val_accuracy: 0.8344 - val_loss: 0.4750\n",
      "Epoch 57/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9338 - loss: 0.1627 - val_accuracy: 0.8180 - val_loss: 0.5231\n",
      "Epoch 58/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9401 - loss: 0.1614 - val_accuracy: 0.8262 - val_loss: 0.4960\n",
      "Epoch 59/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9462 - loss: 0.1402 - val_accuracy: 0.8466 - val_loss: 0.5135\n",
      "Epoch 60/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9396 - loss: 0.1578 - val_accuracy: 0.8344 - val_loss: 0.5628\n",
      "Epoch 61/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9411 - loss: 0.1486 - val_accuracy: 0.8262 - val_loss: 0.5515\n",
      "Epoch 62/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9478 - loss: 0.1323 - val_accuracy: 0.8344 - val_loss: 0.5509\n",
      "Epoch 63/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1267 - val_accuracy: 0.8160 - val_loss: 0.5731\n",
      "Epoch 64/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9520 - loss: 0.1274 - val_accuracy: 0.8282 - val_loss: 0.5646\n",
      "Epoch 65/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9597 - loss: 0.1083 - val_accuracy: 0.8344 - val_loss: 0.5594\n",
      "Epoch 66/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.1061 - val_accuracy: 0.8262 - val_loss: 0.6404\n",
      "Epoch 67/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.1043 - val_accuracy: 0.8384 - val_loss: 0.6498\n",
      "Epoch 68/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.1243 - val_accuracy: 0.8282 - val_loss: 0.6263\n",
      "Epoch 69/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9662 - loss: 0.0921 - val_accuracy: 0.8241 - val_loss: 0.6568\n",
      "Epoch 70/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.0876 - val_accuracy: 0.8098 - val_loss: 0.7210\n",
      "Epoch 71/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9531 - loss: 0.1248 - val_accuracy: 0.8282 - val_loss: 0.6084\n",
      "Epoch 72/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.0858 - val_accuracy: 0.8139 - val_loss: 0.6570\n",
      "Epoch 73/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.0719 - val_accuracy: 0.8241 - val_loss: 0.6708\n",
      "Epoch 74/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.0604 - val_accuracy: 0.8200 - val_loss: 0.7009\n",
      "Epoch 75/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9702 - loss: 0.0810 - val_accuracy: 0.8200 - val_loss: 0.7043\n",
      "Epoch 76/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9775 - loss: 0.0678 - val_accuracy: 0.8119 - val_loss: 0.7299\n",
      "Epoch 77/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9701 - loss: 0.0795 - val_accuracy: 0.8139 - val_loss: 0.7318\n",
      "Epoch 78/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9802 - loss: 0.0659 - val_accuracy: 0.8139 - val_loss: 0.7176\n",
      "Epoch 79/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9692 - loss: 0.0902 - val_accuracy: 0.8384 - val_loss: 0.6578\n",
      "Epoch 80/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9785 - loss: 0.0598 - val_accuracy: 0.8323 - val_loss: 0.7107\n",
      "Epoch 81/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0608 - val_accuracy: 0.8180 - val_loss: 0.7577\n",
      "Epoch 82/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9737 - loss: 0.0747 - val_accuracy: 0.8323 - val_loss: 0.7132\n",
      "Epoch 83/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9776 - loss: 0.0585 - val_accuracy: 0.8364 - val_loss: 0.6985\n",
      "Epoch 84/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0506 - val_accuracy: 0.8241 - val_loss: 0.7834\n",
      "Epoch 85/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0576 - val_accuracy: 0.8139 - val_loss: 0.7285\n",
      "Epoch 86/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.0779 - val_accuracy: 0.8098 - val_loss: 0.8895\n",
      "Epoch 87/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.0498 - val_accuracy: 0.7975 - val_loss: 0.8889\n",
      "Epoch 88/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.0449 - val_accuracy: 0.8200 - val_loss: 0.8588\n",
      "Epoch 89/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0420 - val_accuracy: 0.8180 - val_loss: 0.8591\n",
      "Epoch 90/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0374 - val_accuracy: 0.8139 - val_loss: 0.9268\n",
      "Epoch 91/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0505 - val_accuracy: 0.7996 - val_loss: 0.9832\n",
      "Epoch 92/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9577 - loss: 0.1149 - val_accuracy: 0.8160 - val_loss: 0.8258\n",
      "Epoch 93/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0410 - val_accuracy: 0.8078 - val_loss: 0.8170\n",
      "Epoch 94/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9889 - loss: 0.0320 - val_accuracy: 0.8119 - val_loss: 0.9802\n",
      "Epoch 95/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0577 - val_accuracy: 0.8180 - val_loss: 0.8686\n",
      "Epoch 96/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0304 - val_accuracy: 0.8221 - val_loss: 0.8121\n",
      "Epoch 97/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0747 - val_accuracy: 0.8180 - val_loss: 0.9040\n",
      "Epoch 98/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0393 - val_accuracy: 0.8180 - val_loss: 0.8957\n",
      "Epoch 99/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0284 - val_accuracy: 0.8119 - val_loss: 0.9856\n",
      "Epoch 100/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9736 - loss: 0.0760 - val_accuracy: 0.8139 - val_loss: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │           \u001b[38;5;34m100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m9,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,355</span> (110.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,355\u001b[0m (110.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,451</span> (36.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,451\u001b[0m (36.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,904</span> (73.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m18,904\u001b[0m (73.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(train_seq_Y), epochs=100, batch_size=32, validation_data=(np.array(X_valid), np.array(valid_seq_Y)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = 50,1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def build_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=10, output_dim=10, input_length=input_length))  # For 10 unique characters\n",
    "\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))  # sigmoid for binary classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5097 - loss: 0.6931 - val_accuracy: 0.5317 - val_loss: 0.6913\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 0.6709 - val_accuracy: 0.6892 - val_loss: 0.6174\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6588 - loss: 0.6185 - val_accuracy: 0.6748 - val_loss: 0.5953\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6907 - loss: 0.5865 - val_accuracy: 0.7137 - val_loss: 0.5555\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6990 - loss: 0.5647 - val_accuracy: 0.7280 - val_loss: 0.5304\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.5395 - val_accuracy: 0.7423 - val_loss: 0.5156\n",
      "Epoch 7/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5084 - val_accuracy: 0.7566 - val_loss: 0.4836\n",
      "Epoch 8/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.4924 - val_accuracy: 0.7689 - val_loss: 0.4639\n",
      "Epoch 9/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.4656 - val_accuracy: 0.7914 - val_loss: 0.4529\n",
      "Epoch 10/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.4503 - val_accuracy: 0.7955 - val_loss: 0.4407\n",
      "Epoch 11/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.4108 - val_accuracy: 0.8282 - val_loss: 0.4046\n",
      "Epoch 12/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.3877 - val_accuracy: 0.8548 - val_loss: 0.3840\n",
      "Epoch 13/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8186 - loss: 0.3889 - val_accuracy: 0.8384 - val_loss: 0.3789\n",
      "Epoch 14/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 0.3569 - val_accuracy: 0.8507 - val_loss: 0.3626\n",
      "Epoch 15/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3490 - val_accuracy: 0.8384 - val_loss: 0.3581\n",
      "Epoch 16/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3281 - val_accuracy: 0.8589 - val_loss: 0.3394\n",
      "Epoch 17/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.3164 - val_accuracy: 0.8466 - val_loss: 0.3341\n",
      "Epoch 18/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8680 - loss: 0.2957 - val_accuracy: 0.8630 - val_loss: 0.3100\n",
      "Epoch 19/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.2969 - val_accuracy: 0.8712 - val_loss: 0.2940\n",
      "Epoch 20/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.2834 - val_accuracy: 0.8630 - val_loss: 0.3040\n",
      "Epoch 21/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.2703 - val_accuracy: 0.8630 - val_loss: 0.2921\n",
      "Epoch 22/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2615 - val_accuracy: 0.8896 - val_loss: 0.2754\n",
      "Epoch 23/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2626 - val_accuracy: 0.8834 - val_loss: 0.2665\n",
      "Epoch 24/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2376 - val_accuracy: 0.8957 - val_loss: 0.2531\n",
      "Epoch 25/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9036 - loss: 0.2381 - val_accuracy: 0.8814 - val_loss: 0.2584\n",
      "Epoch 26/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2305 - val_accuracy: 0.8814 - val_loss: 0.2540\n",
      "Epoch 27/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2293 - val_accuracy: 0.9018 - val_loss: 0.2428\n",
      "Epoch 28/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2198 - val_accuracy: 0.8916 - val_loss: 0.2366\n",
      "Epoch 29/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2249 - val_accuracy: 0.8998 - val_loss: 0.2333\n",
      "Epoch 30/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2122 - val_accuracy: 0.8896 - val_loss: 0.2310\n",
      "Epoch 31/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2192 - val_accuracy: 0.8773 - val_loss: 0.2502\n",
      "Epoch 32/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.2055 - val_accuracy: 0.9141 - val_loss: 0.2208\n",
      "Epoch 33/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9187 - loss: 0.2023 - val_accuracy: 0.8937 - val_loss: 0.2245\n",
      "Epoch 34/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.1964 - val_accuracy: 0.8937 - val_loss: 0.2353\n",
      "Epoch 35/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2092 - val_accuracy: 0.9039 - val_loss: 0.2224\n",
      "Epoch 36/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.1937 - val_accuracy: 0.8978 - val_loss: 0.2237\n",
      "Epoch 37/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.1948 - val_accuracy: 0.8937 - val_loss: 0.2121\n",
      "Epoch 38/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.1931 - val_accuracy: 0.9059 - val_loss: 0.2170\n",
      "Epoch 39/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1874 - val_accuracy: 0.9141 - val_loss: 0.2042\n",
      "Epoch 40/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.1895 - val_accuracy: 0.9141 - val_loss: 0.2075\n",
      "Epoch 41/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.1877 - val_accuracy: 0.9059 - val_loss: 0.2149\n",
      "Epoch 42/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.1674 - val_accuracy: 0.9100 - val_loss: 0.2108\n",
      "Epoch 43/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.1776 - val_accuracy: 0.9162 - val_loss: 0.1980\n",
      "Epoch 44/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.1877 - val_accuracy: 0.9223 - val_loss: 0.1926\n",
      "Epoch 45/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1693 - val_accuracy: 0.9202 - val_loss: 0.2045\n",
      "Epoch 46/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9326 - loss: 0.1754 - val_accuracy: 0.9162 - val_loss: 0.1980\n",
      "Epoch 47/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1655 - val_accuracy: 0.9018 - val_loss: 0.2034\n",
      "Epoch 48/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.1633 - val_accuracy: 0.9100 - val_loss: 0.2102\n",
      "Epoch 49/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.1674 - val_accuracy: 0.9141 - val_loss: 0.1840\n",
      "Epoch 50/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1623 - val_accuracy: 0.9182 - val_loss: 0.1978\n",
      "Epoch 51/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.1635 - val_accuracy: 0.9141 - val_loss: 0.1941\n",
      "Epoch 52/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1603 - val_accuracy: 0.9243 - val_loss: 0.1816\n",
      "Epoch 53/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1557 - val_accuracy: 0.9121 - val_loss: 0.1948\n",
      "Epoch 54/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.1516 - val_accuracy: 0.9305 - val_loss: 0.1800\n",
      "Epoch 55/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.1567 - val_accuracy: 0.9202 - val_loss: 0.1843\n",
      "Epoch 56/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1527 - val_accuracy: 0.9243 - val_loss: 0.1870\n",
      "Epoch 57/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1563 - val_accuracy: 0.9243 - val_loss: 0.1831\n",
      "Epoch 58/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1480 - val_accuracy: 0.9162 - val_loss: 0.1869\n",
      "Epoch 59/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1483 - val_accuracy: 0.9182 - val_loss: 0.1826\n",
      "Epoch 60/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.1572 - val_accuracy: 0.9100 - val_loss: 0.1781\n",
      "Epoch 61/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.1534 - val_accuracy: 0.9162 - val_loss: 0.1847\n",
      "Epoch 62/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.1483 - val_accuracy: 0.9305 - val_loss: 0.1821\n",
      "Epoch 63/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1437 - val_accuracy: 0.9182 - val_loss: 0.1795\n",
      "Epoch 64/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9505 - loss: 0.1307 - val_accuracy: 0.9018 - val_loss: 0.1864\n",
      "Epoch 65/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1424 - val_accuracy: 0.9182 - val_loss: 0.1835\n",
      "Epoch 66/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.1428 - val_accuracy: 0.9182 - val_loss: 0.1715\n",
      "Epoch 67/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1444 - val_accuracy: 0.9182 - val_loss: 0.1762\n",
      "Epoch 68/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.1519 - val_accuracy: 0.9182 - val_loss: 0.1812\n",
      "Epoch 69/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.1372 - val_accuracy: 0.9264 - val_loss: 0.1708\n",
      "Epoch 70/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1413 - val_accuracy: 0.9141 - val_loss: 0.1910\n",
      "Epoch 71/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.1490 - val_accuracy: 0.9182 - val_loss: 0.1805\n",
      "Epoch 72/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.1489 - val_accuracy: 0.9121 - val_loss: 0.1854\n",
      "Epoch 73/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1374 - val_accuracy: 0.9284 - val_loss: 0.1956\n",
      "Epoch 74/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1373 - val_accuracy: 0.9305 - val_loss: 0.1721\n",
      "Epoch 75/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1372 - val_accuracy: 0.9141 - val_loss: 0.1816\n",
      "Epoch 76/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1358 - val_accuracy: 0.9223 - val_loss: 0.1845\n",
      "Epoch 77/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1327 - val_accuracy: 0.9346 - val_loss: 0.1687\n",
      "Epoch 78/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.1388 - val_accuracy: 0.9325 - val_loss: 0.1663\n",
      "Epoch 79/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.1360 - val_accuracy: 0.9243 - val_loss: 0.1790\n",
      "Epoch 80/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1345 - val_accuracy: 0.9284 - val_loss: 0.1609\n",
      "Epoch 81/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.1489 - val_accuracy: 0.9284 - val_loss: 0.1855\n",
      "Epoch 82/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.1398 - val_accuracy: 0.9305 - val_loss: 0.1606\n",
      "Epoch 83/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.1255 - val_accuracy: 0.9223 - val_loss: 0.1847\n",
      "Epoch 84/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1375 - val_accuracy: 0.9182 - val_loss: 0.1845\n",
      "Epoch 85/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1323 - val_accuracy: 0.9202 - val_loss: 0.1827\n",
      "Epoch 86/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1308 - val_accuracy: 0.9202 - val_loss: 0.1918\n",
      "Epoch 87/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9516 - loss: 0.1342 - val_accuracy: 0.9223 - val_loss: 0.1684\n",
      "Epoch 88/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9531 - loss: 0.1246 - val_accuracy: 0.9387 - val_loss: 0.1658\n",
      "Epoch 89/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.1296 - val_accuracy: 0.9284 - val_loss: 0.1621\n",
      "Epoch 90/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9516 - loss: 0.1233 - val_accuracy: 0.9284 - val_loss: 0.1817\n",
      "Epoch 91/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1261 - val_accuracy: 0.9284 - val_loss: 0.1669\n",
      "Epoch 92/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1091 - val_accuracy: 0.9202 - val_loss: 0.1702\n",
      "Epoch 93/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1198 - val_accuracy: 0.9264 - val_loss: 0.1987\n",
      "Epoch 94/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.1256 - val_accuracy: 0.9264 - val_loss: 0.1902\n",
      "Epoch 95/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1288 - val_accuracy: 0.9223 - val_loss: 0.1842\n",
      "Epoch 96/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.1346 - val_accuracy: 0.9284 - val_loss: 0.1995\n",
      "Epoch 97/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9524 - loss: 0.1318 - val_accuracy: 0.9243 - val_loss: 0.1725\n",
      "Epoch 98/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.1116 - val_accuracy: 0.9141 - val_loss: 0.1799\n",
      "Epoch 99/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1217 - val_accuracy: 0.9121 - val_loss: 0.2029\n",
      "Epoch 100/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1176 - val_accuracy: 0.9162 - val_loss: 0.2044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,159</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_17 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │           \u001b[38;5;34m100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m736\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m5,159\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,091</span> (109.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,091\u001b[0m (109.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,363</span> (36.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,363\u001b[0m (36.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,728</span> (73.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m18,728\u001b[0m (73.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.fit(np.array(X_train), np.array(train_seq_Y), epochs=100, batch_size=32, validation_data=(np.array(X_valid), np.array(valid_seq_Y)))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Confusion Matrix:\n",
      " [[234  18]\n",
      " [ 29 208]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       252\n",
      "           1       0.92      0.88      0.90       237\n",
      "\n",
      "    accuracy                           0.90       489\n",
      "   macro avg       0.91      0.90      0.90       489\n",
      "weighted avg       0.90      0.90      0.90       489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Predict on the test data (X_test)\n",
    "# Model predicts probabilities, so you need to threshold these to get class labels (0 or 1)\n",
    "y_pred_probs = model.predict(np.array(X_valid))\n",
    "\n",
    "# Step 2: Convert probabilities to binary labels (use threshold 0.5)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Step 3: Generate confusion matrix\n",
    "cm = confusion_matrix(np.array(valid_seq_Y), y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Optional: Print classification report for precision, recall, F1-score\n",
    "report = classification_report(np.array(valid_seq_Y), y_pred)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate_model( train_seq_df , X_valid, valid_seq_Y):\n",
    "\n",
    "    sizes = [0.2,0.4,0.6,0.8,1]\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "    for size in sizes:\n",
    "    #create random subsets of training data\n",
    "        print(f\"size is {size}\")\n",
    "        model_copy = build_cnn()\n",
    "        train_seq_df_sample = train_seq_df.sample(frac=size)\n",
    "        train_seq_X = train_seq_df_sample['input_str'].tolist()\n",
    "        train_seq_Y = train_seq_df_sample['label'].tolist()\n",
    "\n",
    "        X_train = [[int(char) for char in sequence] for sequence in train_seq_X]\n",
    "\n",
    "        model_copy.fit(np.array(X_train), np.array(train_seq_Y), epochs=100, batch_size=32, validation_data=(np.array(X_valid), np.array(valid_seq_Y)))\n",
    "\n",
    "        #return validation and training accuracies of the 2 models\n",
    "        train_accuracy.append(model_copy.history.history['accuracy'][-1])\n",
    "        valid_accuracy.append(model_copy.history.history['val_accuracy'][-1])\n",
    "\n",
    "\n",
    "    \n",
    "    plt.plot(sizes, train_accuracy, label='Training accuracy')\n",
    "    plt.plot(sizes, valid_accuracy, label='Validation accuracy')\n",
    "    plt.xlabel('Training data fraction')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size is 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "c:\\Users\\AADI RACIST\\.conda\\envs\\771_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5264 - loss: 0.6932 - val_accuracy: 0.5092 - val_loss: 0.6930\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5085 - loss: 0.6927 - val_accuracy: 0.4826 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5171 - loss: 0.6914 - val_accuracy: 0.5215 - val_loss: 0.6915\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5932 - loss: 0.6847 - val_accuracy: 0.5419 - val_loss: 0.6872\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5840 - loss: 0.6755 - val_accuracy: 0.5971 - val_loss: 0.6746\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6313 - loss: 0.6505 - val_accuracy: 0.5869 - val_loss: 0.6661\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6514 - loss: 0.6159 - val_accuracy: 0.6196 - val_loss: 0.6557\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6657 - loss: 0.6049 - val_accuracy: 0.6544 - val_loss: 0.6228\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 0.5749 - val_accuracy: 0.6360 - val_loss: 0.6239\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6746 - loss: 0.5853 - val_accuracy: 0.6564 - val_loss: 0.6176\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.5701 - val_accuracy: 0.6789 - val_loss: 0.6108\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6924 - loss: 0.5736 - val_accuracy: 0.6708 - val_loss: 0.6016\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7034 - loss: 0.5577 - val_accuracy: 0.6871 - val_loss: 0.5969\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7215 - loss: 0.5440 - val_accuracy: 0.6687 - val_loss: 0.6007\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7053 - loss: 0.5623 - val_accuracy: 0.7014 - val_loss: 0.5899\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.5408 - val_accuracy: 0.6912 - val_loss: 0.5848\n",
      "Epoch 17/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7262 - loss: 0.5219 - val_accuracy: 0.6830 - val_loss: 0.5868\n",
      "Epoch 18/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.5179 - val_accuracy: 0.6667 - val_loss: 0.6008\n",
      "Epoch 19/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7139 - loss: 0.5430 - val_accuracy: 0.7219 - val_loss: 0.5639\n",
      "Epoch 20/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.5050 - val_accuracy: 0.6871 - val_loss: 0.5792\n",
      "Epoch 21/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.5141 - val_accuracy: 0.7178 - val_loss: 0.5521\n",
      "Epoch 22/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.4853 - val_accuracy: 0.7301 - val_loss: 0.5506\n",
      "Epoch 23/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4441 - val_accuracy: 0.7301 - val_loss: 0.5452\n",
      "Epoch 24/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7599 - loss: 0.4674 - val_accuracy: 0.7198 - val_loss: 0.5399\n",
      "Epoch 25/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4569 - val_accuracy: 0.7260 - val_loss: 0.5285\n",
      "Epoch 26/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.4555 - val_accuracy: 0.7096 - val_loss: 0.5503\n",
      "Epoch 27/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.4123 - val_accuracy: 0.7342 - val_loss: 0.5258\n",
      "Epoch 28/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4316 - val_accuracy: 0.7382 - val_loss: 0.5235\n",
      "Epoch 29/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.4187 - val_accuracy: 0.7301 - val_loss: 0.5186\n",
      "Epoch 30/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8157 - loss: 0.3992 - val_accuracy: 0.7096 - val_loss: 0.5594\n",
      "Epoch 31/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.4150 - val_accuracy: 0.7505 - val_loss: 0.5077\n",
      "Epoch 32/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: 0.3683 - val_accuracy: 0.7485 - val_loss: 0.5090\n",
      "Epoch 33/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.3653 - val_accuracy: 0.7423 - val_loss: 0.5028\n",
      "Epoch 34/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.3687 - val_accuracy: 0.7382 - val_loss: 0.5028\n",
      "Epoch 35/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8441 - loss: 0.3585 - val_accuracy: 0.7689 - val_loss: 0.4948\n",
      "Epoch 36/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3517 - val_accuracy: 0.7648 - val_loss: 0.4965\n",
      "Epoch 37/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.3452 - val_accuracy: 0.7239 - val_loss: 0.5378\n",
      "Epoch 38/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 0.3611 - val_accuracy: 0.7198 - val_loss: 0.5455\n",
      "Epoch 39/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.3495 - val_accuracy: 0.7423 - val_loss: 0.5273\n",
      "Epoch 40/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.3218 - val_accuracy: 0.7382 - val_loss: 0.4981\n",
      "Epoch 41/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 0.3373 - val_accuracy: 0.7505 - val_loss: 0.4933\n",
      "Epoch 42/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.3220 - val_accuracy: 0.7710 - val_loss: 0.4914\n",
      "Epoch 43/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.2962 - val_accuracy: 0.7689 - val_loss: 0.4916\n",
      "Epoch 44/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.3160 - val_accuracy: 0.7628 - val_loss: 0.5090\n",
      "Epoch 45/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8678 - loss: 0.3107 - val_accuracy: 0.7689 - val_loss: 0.4925\n",
      "Epoch 46/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.2948 - val_accuracy: 0.7587 - val_loss: 0.4889\n",
      "Epoch 47/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8814 - loss: 0.2869 - val_accuracy: 0.7546 - val_loss: 0.4904\n",
      "Epoch 48/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8782 - loss: 0.2832 - val_accuracy: 0.7526 - val_loss: 0.5348\n",
      "Epoch 49/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.2544 - val_accuracy: 0.7689 - val_loss: 0.5139\n",
      "Epoch 50/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.2641 - val_accuracy: 0.7587 - val_loss: 0.4969\n",
      "Epoch 51/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.2664 - val_accuracy: 0.7587 - val_loss: 0.5042\n",
      "Epoch 52/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.2906 - val_accuracy: 0.7669 - val_loss: 0.5017\n",
      "Epoch 53/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.2386 - val_accuracy: 0.7648 - val_loss: 0.4917\n",
      "Epoch 54/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8964 - loss: 0.2596 - val_accuracy: 0.7628 - val_loss: 0.5035\n",
      "Epoch 55/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8990 - loss: 0.2324 - val_accuracy: 0.7648 - val_loss: 0.5088\n",
      "Epoch 56/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.2600 - val_accuracy: 0.7526 - val_loss: 0.5026\n",
      "Epoch 57/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2279 - val_accuracy: 0.7628 - val_loss: 0.5243\n",
      "Epoch 58/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2494 - val_accuracy: 0.7669 - val_loss: 0.5065\n",
      "Epoch 59/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.2332 - val_accuracy: 0.7648 - val_loss: 0.5101\n",
      "Epoch 60/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.2406 - val_accuracy: 0.7669 - val_loss: 0.5114\n",
      "Epoch 61/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.2192 - val_accuracy: 0.7648 - val_loss: 0.5190\n",
      "Epoch 62/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.2417 - val_accuracy: 0.7546 - val_loss: 0.5117\n",
      "Epoch 63/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2208 - val_accuracy: 0.7771 - val_loss: 0.5314\n",
      "Epoch 64/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2083 - val_accuracy: 0.7791 - val_loss: 0.5427\n",
      "Epoch 65/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.2396 - val_accuracy: 0.7607 - val_loss: 0.5270\n",
      "Epoch 66/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.2172 - val_accuracy: 0.7628 - val_loss: 0.5314\n",
      "Epoch 67/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.1812 - val_accuracy: 0.7689 - val_loss: 0.5286\n",
      "Epoch 68/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2021 - val_accuracy: 0.7566 - val_loss: 0.5367\n",
      "Epoch 69/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9248 - loss: 0.1988 - val_accuracy: 0.7566 - val_loss: 0.5309\n",
      "Epoch 70/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.1901 - val_accuracy: 0.7648 - val_loss: 0.5392\n",
      "Epoch 71/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.1920 - val_accuracy: 0.7648 - val_loss: 0.5619\n",
      "Epoch 72/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8987 - loss: 0.2161 - val_accuracy: 0.7710 - val_loss: 0.5150\n",
      "Epoch 73/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2081 - val_accuracy: 0.7771 - val_loss: 0.5285\n",
      "Epoch 74/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9362 - loss: 0.1711 - val_accuracy: 0.7648 - val_loss: 0.5336\n",
      "Epoch 75/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2061 - val_accuracy: 0.7771 - val_loss: 0.5242\n",
      "Epoch 76/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.1811 - val_accuracy: 0.7669 - val_loss: 0.5330\n",
      "Epoch 77/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.1725 - val_accuracy: 0.7587 - val_loss: 0.5516\n",
      "Epoch 78/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.1618 - val_accuracy: 0.7669 - val_loss: 0.5696\n",
      "Epoch 79/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.2032 - val_accuracy: 0.7587 - val_loss: 0.5327\n",
      "Epoch 80/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.1860 - val_accuracy: 0.7607 - val_loss: 0.5566\n",
      "Epoch 81/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.1956 - val_accuracy: 0.7710 - val_loss: 0.5430\n",
      "Epoch 82/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.1561 - val_accuracy: 0.7607 - val_loss: 0.5400\n",
      "Epoch 83/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.1765 - val_accuracy: 0.7730 - val_loss: 0.5464\n",
      "Epoch 84/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.1809 - val_accuracy: 0.7689 - val_loss: 0.5498\n",
      "Epoch 85/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.1495 - val_accuracy: 0.7730 - val_loss: 0.5609\n",
      "Epoch 86/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1631 - val_accuracy: 0.7751 - val_loss: 0.5332\n",
      "Epoch 87/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1371 - val_accuracy: 0.7853 - val_loss: 0.5635\n",
      "Epoch 88/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.1392 - val_accuracy: 0.7771 - val_loss: 0.5536\n",
      "Epoch 89/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1643 - val_accuracy: 0.7771 - val_loss: 0.5614\n",
      "Epoch 90/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.1446 - val_accuracy: 0.7873 - val_loss: 0.5593\n",
      "Epoch 91/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.1506 - val_accuracy: 0.7853 - val_loss: 0.5442\n",
      "Epoch 92/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.1503 - val_accuracy: 0.7771 - val_loss: 0.5680\n",
      "Epoch 93/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9426 - loss: 0.1539 - val_accuracy: 0.7710 - val_loss: 0.5577\n",
      "Epoch 94/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.1377 - val_accuracy: 0.7791 - val_loss: 0.5617\n",
      "Epoch 95/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1372 - val_accuracy: 0.7730 - val_loss: 0.5732\n",
      "Epoch 96/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9539 - loss: 0.1345 - val_accuracy: 0.7730 - val_loss: 0.5722\n",
      "Epoch 97/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1442 - val_accuracy: 0.7832 - val_loss: 0.5519\n",
      "Epoch 98/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1490 - val_accuracy: 0.7873 - val_loss: 0.5579\n",
      "Epoch 99/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1359 - val_accuracy: 0.7873 - val_loss: 0.5566\n",
      "Epoch 100/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1418 - val_accuracy: 0.7975 - val_loss: 0.5706\n",
      "size is 0.4\n",
      "Epoch 1/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5224 - loss: 0.6930 - val_accuracy: 0.5153 - val_loss: 0.6927\n",
      "Epoch 2/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5130 - loss: 0.6927 - val_accuracy: 0.5378 - val_loss: 0.6920\n",
      "Epoch 3/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 0.6914 - val_accuracy: 0.5358 - val_loss: 0.6842\n",
      "Epoch 4/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5737 - loss: 0.6756 - val_accuracy: 0.6339 - val_loss: 0.6650\n",
      "Epoch 5/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: 0.6438 - val_accuracy: 0.6237 - val_loss: 0.6381\n",
      "Epoch 6/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.6346 - val_accuracy: 0.6605 - val_loss: 0.6157\n",
      "Epoch 7/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.5858 - val_accuracy: 0.6708 - val_loss: 0.5975\n",
      "Epoch 8/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.5627 - val_accuracy: 0.6953 - val_loss: 0.5785\n",
      "Epoch 9/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5480 - val_accuracy: 0.7178 - val_loss: 0.5765\n",
      "Epoch 10/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5230 - val_accuracy: 0.7198 - val_loss: 0.5454\n",
      "Epoch 11/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7631 - loss: 0.4976 - val_accuracy: 0.7382 - val_loss: 0.5343\n",
      "Epoch 12/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.4709 - val_accuracy: 0.7607 - val_loss: 0.5151\n",
      "Epoch 13/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.4646 - val_accuracy: 0.7464 - val_loss: 0.4975\n",
      "Epoch 14/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.4569 - val_accuracy: 0.7607 - val_loss: 0.4988\n",
      "Epoch 15/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.4347 - val_accuracy: 0.7710 - val_loss: 0.4801\n",
      "Epoch 16/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.4158 - val_accuracy: 0.7464 - val_loss: 0.4897\n",
      "Epoch 17/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4102 - val_accuracy: 0.7975 - val_loss: 0.4666\n",
      "Epoch 18/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.3970 - val_accuracy: 0.7955 - val_loss: 0.4648\n",
      "Epoch 19/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.3741 - val_accuracy: 0.7955 - val_loss: 0.4648\n",
      "Epoch 20/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.3598 - val_accuracy: 0.8139 - val_loss: 0.4479\n",
      "Epoch 21/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.3585 - val_accuracy: 0.8057 - val_loss: 0.4426\n",
      "Epoch 22/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.3681 - val_accuracy: 0.7894 - val_loss: 0.4414\n",
      "Epoch 23/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3440 - val_accuracy: 0.8098 - val_loss: 0.4369\n",
      "Epoch 24/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8432 - loss: 0.3616 - val_accuracy: 0.8139 - val_loss: 0.4253\n",
      "Epoch 25/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3373 - val_accuracy: 0.8098 - val_loss: 0.4409\n",
      "Epoch 26/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 0.3305 - val_accuracy: 0.8323 - val_loss: 0.4080\n",
      "Epoch 27/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.3215 - val_accuracy: 0.8139 - val_loss: 0.4253\n",
      "Epoch 28/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8603 - loss: 0.3174 - val_accuracy: 0.8180 - val_loss: 0.4251\n",
      "Epoch 29/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.2870 - val_accuracy: 0.8200 - val_loss: 0.4089\n",
      "Epoch 30/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.2946 - val_accuracy: 0.8200 - val_loss: 0.4125\n",
      "Epoch 31/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.2819 - val_accuracy: 0.8282 - val_loss: 0.4067\n",
      "Epoch 32/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.2765 - val_accuracy: 0.8200 - val_loss: 0.4032\n",
      "Epoch 33/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2680 - val_accuracy: 0.8262 - val_loss: 0.3976\n",
      "Epoch 34/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.2635 - val_accuracy: 0.8241 - val_loss: 0.3983\n",
      "Epoch 35/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2778 - val_accuracy: 0.8303 - val_loss: 0.3918\n",
      "Epoch 36/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2544 - val_accuracy: 0.8241 - val_loss: 0.4024\n",
      "Epoch 37/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2518 - val_accuracy: 0.8303 - val_loss: 0.3781\n",
      "Epoch 38/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2460 - val_accuracy: 0.8241 - val_loss: 0.3716\n",
      "Epoch 39/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2649 - val_accuracy: 0.8364 - val_loss: 0.3885\n",
      "Epoch 40/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2560 - val_accuracy: 0.8262 - val_loss: 0.3827\n",
      "Epoch 41/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.2620 - val_accuracy: 0.8282 - val_loss: 0.3734\n",
      "Epoch 42/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2296 - val_accuracy: 0.8262 - val_loss: 0.3948\n",
      "Epoch 43/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2172 - val_accuracy: 0.8282 - val_loss: 0.3822\n",
      "Epoch 44/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.2414 - val_accuracy: 0.8303 - val_loss: 0.3719\n",
      "Epoch 45/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.2440 - val_accuracy: 0.8180 - val_loss: 0.3739\n",
      "Epoch 46/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2045 - val_accuracy: 0.8200 - val_loss: 0.3816\n",
      "Epoch 47/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.2189 - val_accuracy: 0.8262 - val_loss: 0.3751\n",
      "Epoch 48/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.2246 - val_accuracy: 0.8282 - val_loss: 0.3750\n",
      "Epoch 49/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2046 - val_accuracy: 0.8384 - val_loss: 0.3608\n",
      "Epoch 50/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.1974 - val_accuracy: 0.8323 - val_loss: 0.3673\n",
      "Epoch 51/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2142 - val_accuracy: 0.8221 - val_loss: 0.3731\n",
      "Epoch 52/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.1873 - val_accuracy: 0.8323 - val_loss: 0.3726\n",
      "Epoch 53/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2117 - val_accuracy: 0.8282 - val_loss: 0.3743\n",
      "Epoch 54/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.1864 - val_accuracy: 0.8405 - val_loss: 0.3677\n",
      "Epoch 55/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1739 - val_accuracy: 0.8364 - val_loss: 0.3930\n",
      "Epoch 56/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.1989 - val_accuracy: 0.8241 - val_loss: 0.3806\n",
      "Epoch 57/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.1863 - val_accuracy: 0.8323 - val_loss: 0.3713\n",
      "Epoch 58/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.1625 - val_accuracy: 0.8466 - val_loss: 0.3772\n",
      "Epoch 59/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.1875 - val_accuracy: 0.8384 - val_loss: 0.3643\n",
      "Epoch 60/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.1659 - val_accuracy: 0.8344 - val_loss: 0.3560\n",
      "Epoch 61/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.1812 - val_accuracy: 0.8282 - val_loss: 0.3783\n",
      "Epoch 62/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1525 - val_accuracy: 0.8446 - val_loss: 0.3704\n",
      "Epoch 63/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.1636 - val_accuracy: 0.8405 - val_loss: 0.3577\n",
      "Epoch 64/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.1680 - val_accuracy: 0.8487 - val_loss: 0.3588\n",
      "Epoch 65/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.1527 - val_accuracy: 0.8589 - val_loss: 0.3557\n",
      "Epoch 66/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.1685 - val_accuracy: 0.8466 - val_loss: 0.3649\n",
      "Epoch 67/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1661 - val_accuracy: 0.8425 - val_loss: 0.3652\n",
      "Epoch 68/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.1675 - val_accuracy: 0.8507 - val_loss: 0.3766\n",
      "Epoch 69/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1461 - val_accuracy: 0.8548 - val_loss: 0.3581\n",
      "Epoch 70/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1554 - val_accuracy: 0.8569 - val_loss: 0.3433\n",
      "Epoch 71/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.1609 - val_accuracy: 0.8487 - val_loss: 0.3472\n",
      "Epoch 72/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1521 - val_accuracy: 0.8364 - val_loss: 0.3687\n",
      "Epoch 73/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.1425 - val_accuracy: 0.8446 - val_loss: 0.3499\n",
      "Epoch 74/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1382 - val_accuracy: 0.8446 - val_loss: 0.3686\n",
      "Epoch 75/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1506 - val_accuracy: 0.8364 - val_loss: 0.3820\n",
      "Epoch 76/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1540 - val_accuracy: 0.8466 - val_loss: 0.3683\n",
      "Epoch 77/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1365 - val_accuracy: 0.8528 - val_loss: 0.3490\n",
      "Epoch 78/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1377 - val_accuracy: 0.8466 - val_loss: 0.3530\n",
      "Epoch 79/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1394 - val_accuracy: 0.8507 - val_loss: 0.3481\n",
      "Epoch 80/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1319 - val_accuracy: 0.8548 - val_loss: 0.3392\n",
      "Epoch 81/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9379 - loss: 0.1573 - val_accuracy: 0.8487 - val_loss: 0.3506\n",
      "Epoch 82/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1233 - val_accuracy: 0.8507 - val_loss: 0.3718\n",
      "Epoch 83/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1276 - val_accuracy: 0.8425 - val_loss: 0.3535\n",
      "Epoch 84/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.1395 - val_accuracy: 0.8487 - val_loss: 0.3669\n",
      "Epoch 85/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.1251 - val_accuracy: 0.8609 - val_loss: 0.3557\n",
      "Epoch 86/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1317 - val_accuracy: 0.8548 - val_loss: 0.3662\n",
      "Epoch 87/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1227 - val_accuracy: 0.8569 - val_loss: 0.3786\n",
      "Epoch 88/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1196 - val_accuracy: 0.8384 - val_loss: 0.3724\n",
      "Epoch 89/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.1433 - val_accuracy: 0.8507 - val_loss: 0.3646\n",
      "Epoch 90/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1171 - val_accuracy: 0.8507 - val_loss: 0.3698\n",
      "Epoch 91/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.1277 - val_accuracy: 0.8466 - val_loss: 0.3960\n",
      "Epoch 92/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1280 - val_accuracy: 0.8425 - val_loss: 0.3874\n",
      "Epoch 93/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1248 - val_accuracy: 0.8507 - val_loss: 0.3651\n",
      "Epoch 94/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1145 - val_accuracy: 0.8487 - val_loss: 0.3796\n",
      "Epoch 95/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1248 - val_accuracy: 0.8446 - val_loss: 0.3819\n",
      "Epoch 96/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1203 - val_accuracy: 0.8569 - val_loss: 0.3848\n",
      "Epoch 97/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1192 - val_accuracy: 0.8446 - val_loss: 0.3872\n",
      "Epoch 98/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1151 - val_accuracy: 0.8589 - val_loss: 0.4029\n",
      "Epoch 99/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1354 - val_accuracy: 0.8548 - val_loss: 0.3724\n",
      "Epoch 100/100\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1036 - val_accuracy: 0.8425 - val_loss: 0.3683\n",
      "size is 0.6\n",
      "Epoch 1/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4836 - loss: 0.6934 - val_accuracy: 0.4847 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5115 - loss: 0.6930 - val_accuracy: 0.5215 - val_loss: 0.6913\n",
      "Epoch 3/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.6750 - val_accuracy: 0.6585 - val_loss: 0.6207\n",
      "Epoch 4/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6556 - loss: 0.6246 - val_accuracy: 0.6933 - val_loss: 0.5887\n",
      "Epoch 5/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6664 - loss: 0.6059 - val_accuracy: 0.7321 - val_loss: 0.5653\n",
      "Epoch 6/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.5751 - val_accuracy: 0.7362 - val_loss: 0.5442\n",
      "Epoch 7/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7245 - loss: 0.5492 - val_accuracy: 0.7587 - val_loss: 0.5133\n",
      "Epoch 8/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.5318 - val_accuracy: 0.7914 - val_loss: 0.4930\n",
      "Epoch 9/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7697 - loss: 0.4812 - val_accuracy: 0.7751 - val_loss: 0.4843\n",
      "Epoch 10/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4796 - val_accuracy: 0.8078 - val_loss: 0.4600\n",
      "Epoch 11/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.4450 - val_accuracy: 0.8180 - val_loss: 0.4470\n",
      "Epoch 12/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4355 - val_accuracy: 0.8098 - val_loss: 0.4326\n",
      "Epoch 13/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.4276 - val_accuracy: 0.8057 - val_loss: 0.4524\n",
      "Epoch 14/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4157 - val_accuracy: 0.8160 - val_loss: 0.4259\n",
      "Epoch 15/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.4005 - val_accuracy: 0.8160 - val_loss: 0.4164\n",
      "Epoch 16/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3906 - val_accuracy: 0.8262 - val_loss: 0.4115\n",
      "Epoch 17/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3804 - val_accuracy: 0.8221 - val_loss: 0.4130\n",
      "Epoch 18/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8248 - loss: 0.3738 - val_accuracy: 0.8221 - val_loss: 0.3983\n",
      "Epoch 19/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.3548 - val_accuracy: 0.8425 - val_loss: 0.3897\n",
      "Epoch 20/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3686 - val_accuracy: 0.8221 - val_loss: 0.3909\n",
      "Epoch 21/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3363 - val_accuracy: 0.8262 - val_loss: 0.3879\n",
      "Epoch 22/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3253 - val_accuracy: 0.8384 - val_loss: 0.3899\n",
      "Epoch 23/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3263 - val_accuracy: 0.8425 - val_loss: 0.3654\n",
      "Epoch 24/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3316 - val_accuracy: 0.8180 - val_loss: 0.3730\n",
      "Epoch 25/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3198 - val_accuracy: 0.8262 - val_loss: 0.3656\n",
      "Epoch 26/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3045 - val_accuracy: 0.8466 - val_loss: 0.3525\n",
      "Epoch 27/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.2922 - val_accuracy: 0.8446 - val_loss: 0.3660\n",
      "Epoch 28/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.2824 - val_accuracy: 0.8364 - val_loss: 0.3551\n",
      "Epoch 29/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.2715 - val_accuracy: 0.8364 - val_loss: 0.3591\n",
      "Epoch 30/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.2797 - val_accuracy: 0.8425 - val_loss: 0.3386\n",
      "Epoch 31/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.2729 - val_accuracy: 0.8466 - val_loss: 0.3379\n",
      "Epoch 32/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.2681 - val_accuracy: 0.8282 - val_loss: 0.3488\n",
      "Epoch 33/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2506 - val_accuracy: 0.8344 - val_loss: 0.3468\n",
      "Epoch 34/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.2494 - val_accuracy: 0.8425 - val_loss: 0.3431\n",
      "Epoch 35/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2644 - val_accuracy: 0.8364 - val_loss: 0.3442\n",
      "Epoch 36/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2539 - val_accuracy: 0.8609 - val_loss: 0.3385\n",
      "Epoch 37/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2566 - val_accuracy: 0.8569 - val_loss: 0.3291\n",
      "Epoch 38/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2399 - val_accuracy: 0.8569 - val_loss: 0.3290\n",
      "Epoch 39/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.2320 - val_accuracy: 0.8384 - val_loss: 0.3288\n",
      "Epoch 40/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2187 - val_accuracy: 0.8650 - val_loss: 0.3217\n",
      "Epoch 41/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2373 - val_accuracy: 0.8466 - val_loss: 0.3246\n",
      "Epoch 42/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2140 - val_accuracy: 0.8548 - val_loss: 0.3204\n",
      "Epoch 43/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2200 - val_accuracy: 0.8630 - val_loss: 0.3149\n",
      "Epoch 44/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2128 - val_accuracy: 0.8691 - val_loss: 0.3042\n",
      "Epoch 45/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.1910 - val_accuracy: 0.8528 - val_loss: 0.3061\n",
      "Epoch 46/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2181 - val_accuracy: 0.8487 - val_loss: 0.3182\n",
      "Epoch 47/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1866 - val_accuracy: 0.8548 - val_loss: 0.3201\n",
      "Epoch 48/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2006 - val_accuracy: 0.8691 - val_loss: 0.3210\n",
      "Epoch 49/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.1930 - val_accuracy: 0.8630 - val_loss: 0.3210\n",
      "Epoch 50/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.1989 - val_accuracy: 0.8671 - val_loss: 0.3041\n",
      "Epoch 51/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.1852 - val_accuracy: 0.8589 - val_loss: 0.3189\n",
      "Epoch 52/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.1780 - val_accuracy: 0.8691 - val_loss: 0.2975\n",
      "Epoch 53/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1574 - val_accuracy: 0.8528 - val_loss: 0.3095\n",
      "Epoch 54/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.1816 - val_accuracy: 0.8569 - val_loss: 0.3244\n",
      "Epoch 55/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.1811 - val_accuracy: 0.8630 - val_loss: 0.3053\n",
      "Epoch 56/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.1757 - val_accuracy: 0.8650 - val_loss: 0.3084\n",
      "Epoch 57/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9318 - loss: 0.1736 - val_accuracy: 0.8630 - val_loss: 0.3071\n",
      "Epoch 58/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9284 - loss: 0.1723 - val_accuracy: 0.8712 - val_loss: 0.3072\n",
      "Epoch 59/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9248 - loss: 0.1678 - val_accuracy: 0.8712 - val_loss: 0.3054\n",
      "Epoch 60/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9344 - loss: 0.1711 - val_accuracy: 0.8773 - val_loss: 0.2949\n",
      "Epoch 61/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9372 - loss: 0.1575 - val_accuracy: 0.8671 - val_loss: 0.2937\n",
      "Epoch 62/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9359 - loss: 0.1607 - val_accuracy: 0.8691 - val_loss: 0.3183\n",
      "Epoch 63/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.1758 - val_accuracy: 0.8773 - val_loss: 0.2996\n",
      "Epoch 64/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1612 - val_accuracy: 0.8671 - val_loss: 0.2972\n",
      "Epoch 65/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9296 - loss: 0.1683 - val_accuracy: 0.8691 - val_loss: 0.3015\n",
      "Epoch 66/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9307 - loss: 0.1567 - val_accuracy: 0.8732 - val_loss: 0.3005\n",
      "Epoch 67/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.1688 - val_accuracy: 0.8712 - val_loss: 0.3078\n",
      "Epoch 68/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9395 - loss: 0.1502 - val_accuracy: 0.8650 - val_loss: 0.2996\n",
      "Epoch 69/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9373 - loss: 0.1657 - val_accuracy: 0.8814 - val_loss: 0.2821\n",
      "Epoch 70/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9450 - loss: 0.1410 - val_accuracy: 0.8630 - val_loss: 0.3082\n",
      "Epoch 71/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9401 - loss: 0.1443 - val_accuracy: 0.8650 - val_loss: 0.2832\n",
      "Epoch 72/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.1533 - val_accuracy: 0.8773 - val_loss: 0.2943\n",
      "Epoch 73/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.1485 - val_accuracy: 0.8814 - val_loss: 0.2827\n",
      "Epoch 74/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9409 - loss: 0.1481 - val_accuracy: 0.8978 - val_loss: 0.2761\n",
      "Epoch 75/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.1477 - val_accuracy: 0.8875 - val_loss: 0.2869\n",
      "Epoch 76/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.1297 - val_accuracy: 0.8896 - val_loss: 0.2953\n",
      "Epoch 77/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1218 - val_accuracy: 0.8814 - val_loss: 0.2852\n",
      "Epoch 78/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.1310 - val_accuracy: 0.8793 - val_loss: 0.2954\n",
      "Epoch 79/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9513 - loss: 0.1216 - val_accuracy: 0.8548 - val_loss: 0.3059\n",
      "Epoch 80/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.1314 - val_accuracy: 0.8753 - val_loss: 0.2869\n",
      "Epoch 81/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9412 - loss: 0.1486 - val_accuracy: 0.8773 - val_loss: 0.2928\n",
      "Epoch 82/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9483 - loss: 0.1301 - val_accuracy: 0.8937 - val_loss: 0.2806\n",
      "Epoch 83/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9513 - loss: 0.1307 - val_accuracy: 0.8773 - val_loss: 0.2854\n",
      "Epoch 84/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9436 - loss: 0.1285 - val_accuracy: 0.8875 - val_loss: 0.2975\n",
      "Epoch 85/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9394 - loss: 0.1386 - val_accuracy: 0.8834 - val_loss: 0.2730\n",
      "Epoch 86/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1243 - val_accuracy: 0.8691 - val_loss: 0.3083\n",
      "Epoch 87/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9511 - loss: 0.1276 - val_accuracy: 0.8753 - val_loss: 0.2946\n",
      "Epoch 88/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9506 - loss: 0.1299 - val_accuracy: 0.8773 - val_loss: 0.3037\n",
      "Epoch 89/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1249 - val_accuracy: 0.8691 - val_loss: 0.2966\n",
      "Epoch 90/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.1303 - val_accuracy: 0.8671 - val_loss: 0.2890\n",
      "Epoch 91/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.1260 - val_accuracy: 0.8814 - val_loss: 0.2879\n",
      "Epoch 92/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9445 - loss: 0.1381 - val_accuracy: 0.8855 - val_loss: 0.2761\n",
      "Epoch 93/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.1155 - val_accuracy: 0.8875 - val_loss: 0.2653\n",
      "Epoch 94/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1203 - val_accuracy: 0.8855 - val_loss: 0.2842\n",
      "Epoch 95/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.1326 - val_accuracy: 0.8916 - val_loss: 0.2645\n",
      "Epoch 96/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9594 - loss: 0.1101 - val_accuracy: 0.8855 - val_loss: 0.2902\n",
      "Epoch 97/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.1256 - val_accuracy: 0.8712 - val_loss: 0.3071\n",
      "Epoch 98/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.1123 - val_accuracy: 0.8793 - val_loss: 0.2747\n",
      "Epoch 99/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9575 - loss: 0.1123 - val_accuracy: 0.8753 - val_loss: 0.2774\n",
      "Epoch 100/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9519 - loss: 0.1193 - val_accuracy: 0.8793 - val_loss: 0.2897\n",
      "size is 0.8\n",
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4945 - loss: 0.6934 - val_accuracy: 0.5153 - val_loss: 0.6921\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5412 - loss: 0.6882 - val_accuracy: 0.6380 - val_loss: 0.6373\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.6420 - val_accuracy: 0.6973 - val_loss: 0.5950\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6730 - loss: 0.6006 - val_accuracy: 0.7137 - val_loss: 0.5797\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6851 - loss: 0.5887 - val_accuracy: 0.7342 - val_loss: 0.5692\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6841 - loss: 0.5754 - val_accuracy: 0.7444 - val_loss: 0.5580\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5464 - val_accuracy: 0.7362 - val_loss: 0.5350\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5290 - val_accuracy: 0.7342 - val_loss: 0.5429\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.5124 - val_accuracy: 0.7812 - val_loss: 0.4908\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7628 - loss: 0.4872 - val_accuracy: 0.7996 - val_loss: 0.4595\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4405 - val_accuracy: 0.8057 - val_loss: 0.4487\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.4326 - val_accuracy: 0.8344 - val_loss: 0.4224\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.4152 - val_accuracy: 0.8303 - val_loss: 0.4035\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.4041 - val_accuracy: 0.8262 - val_loss: 0.3991\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.3949 - val_accuracy: 0.8405 - val_loss: 0.3871\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3628 - val_accuracy: 0.8364 - val_loss: 0.3767\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.3562 - val_accuracy: 0.8528 - val_loss: 0.3554\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3692 - val_accuracy: 0.8507 - val_loss: 0.3473\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3411 - val_accuracy: 0.8569 - val_loss: 0.3638\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3315 - val_accuracy: 0.8487 - val_loss: 0.3471\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3288 - val_accuracy: 0.8609 - val_loss: 0.3362\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3167 - val_accuracy: 0.8691 - val_loss: 0.3284\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.2981 - val_accuracy: 0.8650 - val_loss: 0.3253\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.2990 - val_accuracy: 0.8630 - val_loss: 0.3159\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.2872 - val_accuracy: 0.8855 - val_loss: 0.3048\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.2597 - val_accuracy: 0.8814 - val_loss: 0.3118\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2700 - val_accuracy: 0.8630 - val_loss: 0.2987\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2715 - val_accuracy: 0.8691 - val_loss: 0.2966\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2503 - val_accuracy: 0.8855 - val_loss: 0.2873\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2505 - val_accuracy: 0.8609 - val_loss: 0.2893\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2441 - val_accuracy: 0.8773 - val_loss: 0.2818\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.2308 - val_accuracy: 0.8712 - val_loss: 0.2855\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2357 - val_accuracy: 0.8793 - val_loss: 0.2703\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2419 - val_accuracy: 0.8671 - val_loss: 0.2857\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2326 - val_accuracy: 0.8712 - val_loss: 0.2639\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2108 - val_accuracy: 0.8753 - val_loss: 0.2762\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2167 - val_accuracy: 0.8691 - val_loss: 0.2685\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2017 - val_accuracy: 0.8814 - val_loss: 0.2664\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2106 - val_accuracy: 0.8855 - val_loss: 0.2491\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2026 - val_accuracy: 0.8691 - val_loss: 0.2624\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.1967 - val_accuracy: 0.8793 - val_loss: 0.2542\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.1892 - val_accuracy: 0.8957 - val_loss: 0.2508\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.1938 - val_accuracy: 0.9059 - val_loss: 0.2475\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.1897 - val_accuracy: 0.8978 - val_loss: 0.2556\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.1855 - val_accuracy: 0.8937 - val_loss: 0.2433\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.1831 - val_accuracy: 0.8916 - val_loss: 0.2354\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.1876 - val_accuracy: 0.8875 - val_loss: 0.2440\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.1867 - val_accuracy: 0.8793 - val_loss: 0.2672\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1785 - val_accuracy: 0.9018 - val_loss: 0.2264\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.1790 - val_accuracy: 0.8937 - val_loss: 0.2533\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.1755 - val_accuracy: 0.9018 - val_loss: 0.2293\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.1602 - val_accuracy: 0.9018 - val_loss: 0.2262\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.1744 - val_accuracy: 0.9018 - val_loss: 0.2234\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1622 - val_accuracy: 0.9039 - val_loss: 0.2333\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1718 - val_accuracy: 0.8998 - val_loss: 0.2395\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1675 - val_accuracy: 0.9018 - val_loss: 0.2385\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1611 - val_accuracy: 0.9018 - val_loss: 0.2360\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1577 - val_accuracy: 0.9018 - val_loss: 0.2254\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1696 - val_accuracy: 0.8957 - val_loss: 0.2371\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.1591 - val_accuracy: 0.9121 - val_loss: 0.2169\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1535 - val_accuracy: 0.9059 - val_loss: 0.2351\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1639 - val_accuracy: 0.8957 - val_loss: 0.2404\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.1601 - val_accuracy: 0.8937 - val_loss: 0.2568\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.1529 - val_accuracy: 0.9100 - val_loss: 0.2368\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1493 - val_accuracy: 0.9039 - val_loss: 0.2405\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.1527 - val_accuracy: 0.9039 - val_loss: 0.2414\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1537 - val_accuracy: 0.9039 - val_loss: 0.2234\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1526 - val_accuracy: 0.9039 - val_loss: 0.2260\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1490 - val_accuracy: 0.9018 - val_loss: 0.2380\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.1590 - val_accuracy: 0.9039 - val_loss: 0.2252\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1315 - val_accuracy: 0.8896 - val_loss: 0.2428\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1540 - val_accuracy: 0.9018 - val_loss: 0.2183\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1521 - val_accuracy: 0.8998 - val_loss: 0.2247\n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.1504 - val_accuracy: 0.9039 - val_loss: 0.2524\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1364 - val_accuracy: 0.9121 - val_loss: 0.2330\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1273 - val_accuracy: 0.9141 - val_loss: 0.2198\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1188 - val_accuracy: 0.8998 - val_loss: 0.2405\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.1506 - val_accuracy: 0.9039 - val_loss: 0.2452\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1364 - val_accuracy: 0.9039 - val_loss: 0.2251\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1404 - val_accuracy: 0.9121 - val_loss: 0.2409\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1264 - val_accuracy: 0.8916 - val_loss: 0.2490\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.1311 - val_accuracy: 0.8998 - val_loss: 0.2573\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1294 - val_accuracy: 0.8978 - val_loss: 0.2470\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.1329 - val_accuracy: 0.9080 - val_loss: 0.2311\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1160 - val_accuracy: 0.9039 - val_loss: 0.2630\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1250 - val_accuracy: 0.8957 - val_loss: 0.2511\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1223 - val_accuracy: 0.8998 - val_loss: 0.2350\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1197 - val_accuracy: 0.9182 - val_loss: 0.2145\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1276 - val_accuracy: 0.8978 - val_loss: 0.2413\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.1226 - val_accuracy: 0.8937 - val_loss: 0.2555\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1383 - val_accuracy: 0.8978 - val_loss: 0.2450\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1187 - val_accuracy: 0.9100 - val_loss: 0.2333\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1198 - val_accuracy: 0.9039 - val_loss: 0.2348\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1303 - val_accuracy: 0.8916 - val_loss: 0.2740\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1260 - val_accuracy: 0.9080 - val_loss: 0.2297\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1300 - val_accuracy: 0.9223 - val_loss: 0.2246\n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1175 - val_accuracy: 0.8957 - val_loss: 0.2572\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1226 - val_accuracy: 0.9059 - val_loss: 0.2596\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1311 - val_accuracy: 0.9080 - val_loss: 0.2505\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1120 - val_accuracy: 0.9182 - val_loss: 0.2327\n",
      "size is 1\n",
      "Epoch 1/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5200 - loss: 0.6925 - val_accuracy: 0.5256 - val_loss: 0.6930\n",
      "Epoch 2/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 0.6914 - val_accuracy: 0.6605 - val_loss: 0.6340\n",
      "Epoch 3/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6422 - loss: 0.6297 - val_accuracy: 0.6953 - val_loss: 0.5978\n",
      "Epoch 4/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6687 - loss: 0.6071 - val_accuracy: 0.7096 - val_loss: 0.5776\n",
      "Epoch 5/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6792 - loss: 0.5856 - val_accuracy: 0.7198 - val_loss: 0.5635\n",
      "Epoch 6/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6992 - loss: 0.5637 - val_accuracy: 0.7362 - val_loss: 0.5394\n",
      "Epoch 7/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.5430 - val_accuracy: 0.7526 - val_loss: 0.5190\n",
      "Epoch 8/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.5134 - val_accuracy: 0.7689 - val_loss: 0.4892\n",
      "Epoch 9/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.4794 - val_accuracy: 0.7873 - val_loss: 0.4624\n",
      "Epoch 10/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4461 - val_accuracy: 0.8098 - val_loss: 0.4413\n",
      "Epoch 11/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.4266 - val_accuracy: 0.7955 - val_loss: 0.4316\n",
      "Epoch 12/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.4031 - val_accuracy: 0.8344 - val_loss: 0.3984\n",
      "Epoch 13/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.3848 - val_accuracy: 0.8344 - val_loss: 0.3757\n",
      "Epoch 14/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3673 - val_accuracy: 0.8344 - val_loss: 0.3746\n",
      "Epoch 15/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3355 - val_accuracy: 0.8548 - val_loss: 0.3541\n",
      "Epoch 16/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3228 - val_accuracy: 0.8446 - val_loss: 0.3421\n",
      "Epoch 17/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3314 - val_accuracy: 0.8609 - val_loss: 0.3180\n",
      "Epoch 18/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8720 - loss: 0.3058 - val_accuracy: 0.8712 - val_loss: 0.3175\n",
      "Epoch 19/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2864 - val_accuracy: 0.8569 - val_loss: 0.3227\n",
      "Epoch 20/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.2922 - val_accuracy: 0.8609 - val_loss: 0.2993\n",
      "Epoch 21/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.2801 - val_accuracy: 0.8650 - val_loss: 0.3054\n",
      "Epoch 22/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.2711 - val_accuracy: 0.8589 - val_loss: 0.2959\n",
      "Epoch 23/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2571 - val_accuracy: 0.8793 - val_loss: 0.2753\n",
      "Epoch 24/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2586 - val_accuracy: 0.8814 - val_loss: 0.2702\n",
      "Epoch 25/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2481 - val_accuracy: 0.8978 - val_loss: 0.2623\n",
      "Epoch 26/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2414 - val_accuracy: 0.8957 - val_loss: 0.2676\n",
      "Epoch 27/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2472 - val_accuracy: 0.8875 - val_loss: 0.2644\n",
      "Epoch 28/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.2337 - val_accuracy: 0.8916 - val_loss: 0.2465\n",
      "Epoch 29/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2174 - val_accuracy: 0.8916 - val_loss: 0.2483\n",
      "Epoch 30/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2366 - val_accuracy: 0.8998 - val_loss: 0.2286\n",
      "Epoch 31/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.2239 - val_accuracy: 0.8793 - val_loss: 0.2631\n",
      "Epoch 32/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2110 - val_accuracy: 0.8978 - val_loss: 0.2369\n",
      "Epoch 33/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2090 - val_accuracy: 0.9141 - val_loss: 0.2185\n",
      "Epoch 34/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2069 - val_accuracy: 0.9018 - val_loss: 0.2295\n",
      "Epoch 35/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2052 - val_accuracy: 0.9080 - val_loss: 0.2119\n",
      "Epoch 36/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.1904 - val_accuracy: 0.9018 - val_loss: 0.2174\n",
      "Epoch 37/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.1995 - val_accuracy: 0.9121 - val_loss: 0.2197\n",
      "Epoch 38/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.1945 - val_accuracy: 0.9121 - val_loss: 0.2230\n",
      "Epoch 39/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.1853 - val_accuracy: 0.9080 - val_loss: 0.2187\n",
      "Epoch 40/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.1937 - val_accuracy: 0.9039 - val_loss: 0.2119\n",
      "Epoch 41/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.1965 - val_accuracy: 0.9018 - val_loss: 0.2210\n",
      "Epoch 42/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.1923 - val_accuracy: 0.9141 - val_loss: 0.2144\n",
      "Epoch 43/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.1903 - val_accuracy: 0.9039 - val_loss: 0.2059\n",
      "Epoch 44/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.1745 - val_accuracy: 0.9223 - val_loss: 0.2023\n",
      "Epoch 45/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.1818 - val_accuracy: 0.9080 - val_loss: 0.2116\n",
      "Epoch 46/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.1686 - val_accuracy: 0.9182 - val_loss: 0.2039\n",
      "Epoch 47/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.1671 - val_accuracy: 0.9202 - val_loss: 0.2059\n",
      "Epoch 48/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.1690 - val_accuracy: 0.9141 - val_loss: 0.2104\n",
      "Epoch 49/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.1746 - val_accuracy: 0.9223 - val_loss: 0.1967\n",
      "Epoch 50/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1697 - val_accuracy: 0.9059 - val_loss: 0.2189\n",
      "Epoch 51/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.1606 - val_accuracy: 0.9059 - val_loss: 0.2063\n",
      "Epoch 52/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.1674 - val_accuracy: 0.9202 - val_loss: 0.1949\n",
      "Epoch 53/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1601 - val_accuracy: 0.9039 - val_loss: 0.2135\n",
      "Epoch 54/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1598 - val_accuracy: 0.9162 - val_loss: 0.2020\n",
      "Epoch 55/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1558 - val_accuracy: 0.9039 - val_loss: 0.2091\n",
      "Epoch 56/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.1686 - val_accuracy: 0.9223 - val_loss: 0.2041\n",
      "Epoch 57/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.1591 - val_accuracy: 0.9121 - val_loss: 0.1991\n",
      "Epoch 58/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1505 - val_accuracy: 0.9018 - val_loss: 0.2213\n",
      "Epoch 59/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1489 - val_accuracy: 0.9162 - val_loss: 0.2139\n",
      "Epoch 60/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1642 - val_accuracy: 0.9059 - val_loss: 0.2151\n",
      "Epoch 61/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1406 - val_accuracy: 0.9121 - val_loss: 0.2091\n",
      "Epoch 62/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.1541 - val_accuracy: 0.9182 - val_loss: 0.2014\n",
      "Epoch 63/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.1555 - val_accuracy: 0.9141 - val_loss: 0.2132\n",
      "Epoch 64/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1430 - val_accuracy: 0.9346 - val_loss: 0.1978\n",
      "Epoch 65/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1516 - val_accuracy: 0.9223 - val_loss: 0.1924\n",
      "Epoch 66/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1387 - val_accuracy: 0.9121 - val_loss: 0.2010\n",
      "Epoch 67/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1469 - val_accuracy: 0.9141 - val_loss: 0.1976\n",
      "Epoch 68/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1462 - val_accuracy: 0.9305 - val_loss: 0.1992\n",
      "Epoch 69/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1405 - val_accuracy: 0.9162 - val_loss: 0.1966\n",
      "Epoch 70/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.1405 - val_accuracy: 0.9100 - val_loss: 0.2172\n",
      "Epoch 71/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1392 - val_accuracy: 0.9223 - val_loss: 0.2196\n",
      "Epoch 72/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9440 - loss: 0.1407 - val_accuracy: 0.9202 - val_loss: 0.2119\n",
      "Epoch 73/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1357 - val_accuracy: 0.9100 - val_loss: 0.2181\n",
      "Epoch 74/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1308 - val_accuracy: 0.9100 - val_loss: 0.2234\n",
      "Epoch 75/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1412 - val_accuracy: 0.9202 - val_loss: 0.2128\n",
      "Epoch 76/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1310 - val_accuracy: 0.9121 - val_loss: 0.2281\n",
      "Epoch 77/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1378 - val_accuracy: 0.9264 - val_loss: 0.2021\n",
      "Epoch 78/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9473 - loss: 0.1340 - val_accuracy: 0.8978 - val_loss: 0.2648\n",
      "Epoch 79/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1153 - val_accuracy: 0.9162 - val_loss: 0.2389\n",
      "Epoch 80/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1365 - val_accuracy: 0.9039 - val_loss: 0.2133\n",
      "Epoch 81/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1262 - val_accuracy: 0.9018 - val_loss: 0.2290\n",
      "Epoch 82/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.1335 - val_accuracy: 0.9305 - val_loss: 0.2028\n",
      "Epoch 83/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1348 - val_accuracy: 0.9182 - val_loss: 0.2212\n",
      "Epoch 84/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1267 - val_accuracy: 0.9100 - val_loss: 0.2149\n",
      "Epoch 85/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.1276 - val_accuracy: 0.9243 - val_loss: 0.2029\n",
      "Epoch 86/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1445 - val_accuracy: 0.9202 - val_loss: 0.1992\n",
      "Epoch 87/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.1382 - val_accuracy: 0.9264 - val_loss: 0.2048\n",
      "Epoch 88/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1301 - val_accuracy: 0.9346 - val_loss: 0.2059\n",
      "Epoch 89/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1273 - val_accuracy: 0.9141 - val_loss: 0.2200\n",
      "Epoch 90/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.1353 - val_accuracy: 0.9243 - val_loss: 0.1952\n",
      "Epoch 91/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1297 - val_accuracy: 0.9202 - val_loss: 0.2033\n",
      "Epoch 92/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1202 - val_accuracy: 0.8998 - val_loss: 0.2165\n",
      "Epoch 93/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1268 - val_accuracy: 0.9202 - val_loss: 0.2201\n",
      "Epoch 94/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1276 - val_accuracy: 0.9243 - val_loss: 0.1967\n",
      "Epoch 95/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1241 - val_accuracy: 0.9202 - val_loss: 0.2101\n",
      "Epoch 96/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1249 - val_accuracy: 0.9264 - val_loss: 0.2216\n",
      "Epoch 97/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1178 - val_accuracy: 0.9080 - val_loss: 0.2339\n",
      "Epoch 98/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1155 - val_accuracy: 0.9162 - val_loss: 0.2275\n",
      "Epoch 99/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1261 - val_accuracy: 0.9243 - val_loss: 0.2089\n",
      "Epoch 100/100\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1233 - val_accuracy: 0.9080 - val_loss: 0.2271\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(train_seq_df, X_valid, valid_seq_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "771_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
